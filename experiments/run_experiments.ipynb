{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Purpose Exp Notebook \n",
    "\n",
    "This notebook has sections to train models, create uncertainty wrappers, and test the models. Experiment specific details are assumed to be contained in `config.py` in the experiment folder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "EXP_FOLDER = 'MNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(EXP_FOLDER))\n",
    "import config # imported from EXP_FOLDER\n",
    "import cProfile\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save models\n",
    "Trains an ensemble of models as specified in config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nn_ood.utils.train import train_ensemble\n",
    "models = train_ensemble(config.N_MODELS, \n",
    "                        config.make_model, \n",
    "                        config.dataset_class, \n",
    "                        config.dist_fam, \n",
    "                        config.opt_class,\n",
    "                        config.opt_kwargs,\n",
    "                        config.sched_class,\n",
    "                        config.sched_kwargs,\n",
    "                        config.device,\n",
    "                        num_epochs=config.N_EPOCHS,\n",
    "                        batch_size=config.BATCH_SIZE)\n",
    "\n",
    "\n",
    "## SAVE MODEL\n",
    "print(\"saving models\")\n",
    "save_folder = os.path.join(EXP_FOLDER, 'models')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    filename = os.path.join(EXP_FOLDER, \"models\", config.FILENAME + \"_%d\" % i)\n",
    "    torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data to create uncertainty wrappers\n",
    "Loops over data to create uncertainty wrappers, and saves them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_folder = os.path.join(EXP_FOLDER, 'times')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "## SET UP MODEL\n",
    "model = config.make_model()\n",
    "\n",
    "## LOAD MODEL\n",
    "filename = os.path.join(EXP_FOLDER, \"models\", config.FILENAME + \"_0\" )\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model = model.to(config.device)\n",
    "model.eval()\n",
    "\n",
    "## SETUP DATASET\n",
    "dataset = config.dataset_class(\"train\", N=5000)\n",
    "\n",
    "## SET UP UNC WRAPPERS\n",
    "for name, info in config.prep_unc_models.items():\n",
    "    print(name)\n",
    "    \n",
    "    config.unfreeze_model(model)\n",
    "    if 'freeze' in info:\n",
    "        if type(info['freeze']) is bool:\n",
    "            freeze_frac = None\n",
    "        else:\n",
    "            freeze_frac = info['freeze']\n",
    "        config.freeze_model(model, freeze_frac=freeze_frac)        \n",
    "    \n",
    "    if 'apply_fn' is info:\n",
    "        model.apply(info['apply_fn'])\n",
    "\n",
    "    unc_model = info['class'](model, config.dist_fam, info['kwargs'])\n",
    "\n",
    "    cProfile.run(\"\"\"\\n\n",
    "unc_model.process_dataset(dataset)\n",
    "    \"\"\", os.path.join(EXP_FOLDER, \"times\", name+\"_process.timing\") )\n",
    "\n",
    "    filename = os.path.join(EXP_FOLDER, \"models\", name+\"_\"+config.FILENAME)\n",
    "    torch.save(unc_model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del model\n",
    "del unc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Uncertainty Wrappers\n",
    "Evaluates prediction and uncertainty estimate on various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_ood.utils.test import process_datasets\n",
    "\n",
    "# LOAD UNC_WRAPPERS\n",
    "print(\"Loading models\")\n",
    "models = []\n",
    "for i in range(config.N_MODELS):\n",
    "    print(\"loading model %d\" % i)\n",
    "    filename = os.path.join(EXP_FOLDER, 'models', config.FILENAME + \"_%d\" % i)\n",
    "    state_dict = torch.load(filename)\n",
    "    model = config.make_model()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    model.to(config.device)\n",
    "    models.append(model)\n",
    "\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test against OoD datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = os.path.join(EXP_FOLDER, 'results')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "save_folder = os.path.join(EXP_FOLDER, 'times')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "for name, info in config.test_unc_models.items():\n",
    "    print(name)\n",
    "    \n",
    "    config.unfreeze_model(model)\n",
    "    if 'freeze' in info:\n",
    "        if type(info['freeze']) is bool:\n",
    "            freeze_frac = None\n",
    "        else:\n",
    "            freeze_frac = info['freeze']\n",
    "        config.freeze_model(model, freeze_frac=freeze_frac)        \n",
    "    \n",
    "    if 'apply_fn' is info:\n",
    "        model.apply(info['apply_fn'])\n",
    "        \n",
    "    if 'multi_model' in info:\n",
    "        unc_model = info['class'](models, config.dist_fam, info['kwargs'])\n",
    "    else:\n",
    "        unc_model = info['class'](model, config.dist_fam, info['kwargs'])\n",
    "    \n",
    "    if info['load_name'] is not None: \n",
    "        filename = os.path.join(EXP_FOLDER, \"models\", info['load_name']+\"_\"+config.FILENAME)\n",
    "        print(filename)\n",
    "        unc_model.load_state_dict(torch.load(filename))\n",
    "        unc_model.cuda()\n",
    "    \n",
    "    try:\n",
    "        cProfile.run(\"\"\"\\n\n",
    "results = process_datasets(config.dataset_class, \n",
    "                           config.test_dataset_args,\n",
    "                           unc_model, \n",
    "                           config.device,\n",
    "                           N=1000,\n",
    "                           **info['forward_kwargs'])\n",
    "        \"\"\", os.path.join(EXP_FOLDER, \"times\", name) )\n",
    "        savepath = os.path.join(EXP_FOLDER, \"results\", name)\n",
    "        torch.save(results, savepath)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test against noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_ood.utils.test import transform_sweep\n",
    "\n",
    "if \"transforms\" not in dir(config):\n",
    "    raise NameError(\"No transforms to test for this experiment\")\n",
    "    \n",
    "save_folder = os.path.join(EXP_FOLDER, 'results_transforms')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "save_folder = os.path.join(EXP_FOLDER, 'times_transforms')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "for name, info in config.test_unc_models.items():\n",
    "    print(name)\n",
    "    \n",
    "    config.unfreeze_model(model)\n",
    "    if 'freeze' in info:\n",
    "        if type(info['freeze']) is bool:\n",
    "            freeze_frac = None\n",
    "        else:\n",
    "            freeze_frac = info['freeze']\n",
    "        config.freeze_model(model, freeze_frac=freeze_frac)        \n",
    "    \n",
    "    if 'apply_fn' is info:\n",
    "        model.apply(info['apply_fn'])\n",
    "        \n",
    "    if 'multi_model' in info:\n",
    "        unc_model = info['class'](models, config.dist_fam, info['kwargs'])\n",
    "    else:\n",
    "        unc_model = info['class'](model, config.dist_fam, info['kwargs'])\n",
    "    \n",
    "    if info['load_name'] is not None: \n",
    "        filename = os.path.join(EXP_FOLDER, \"models\", info['load_name']+\"_\"+config.FILENAME)\n",
    "        print(filename)\n",
    "        unc_model.load_state_dict(torch.load(filename))\n",
    "        unc_model.cuda()\n",
    "    \n",
    "\n",
    "    dataset = config.dataset_class(config.in_dist_splits[0],N=1000)\n",
    "    cProfile.run(\"\"\"\\n\n",
    "results = transform_sweep(dataset, \n",
    "                      config.transforms,\n",
    "                      unc_model, \n",
    "                      config.device,\n",
    "                      **info['forward_kwargs'])\n",
    "    \"\"\", os.path.join(EXP_FOLDER, \"times\", name) )\n",
    "    savepath = os.path.join(EXP_FOLDER, \"results\", name)\n",
    "    torch.save(results, savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
